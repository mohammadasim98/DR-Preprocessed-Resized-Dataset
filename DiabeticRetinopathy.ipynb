{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DiabeticRetinopathy.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V805U1eXniml",
        "I-Z8kF6sMhhj",
        "mKxvwR1rfcM5",
        "8rLz4UORI0Y-",
        "e0w9vLdDKROL",
        "pAEKEI7FmXaf",
        "y38ODUhadSBq",
        "e6sZnsoKmeQz",
        "8df7KL9ofrHZ",
        "a3aLuzJFWw2b",
        "wXgEPFCPIj1V",
        "MThg6a6jHr4v",
        "oMGUK_LaLogS",
        "gMSHKqZOk-Hx"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq8KGmBT5YVI"
      },
      "source": [
        "# **Table Of Content**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Syo1XOyBfh1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_7h-xaYFs7j"
      },
      "source": [
        "import tensorflow as tf\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA8TdS3E7WYn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11384211-3319-4228-9053-477825d7a429"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTjfHa6j5Zi6",
        "colab_type": "toc"
      },
      "source": [
        ">[Table Of Content](#scrollTo=Nq8KGmBT5YVI)\n",
        "\n",
        ">[Group Members](#scrollTo=lmMB_d4mhT_y)\n",
        "\n",
        ">[Importing all the required Libraries](#scrollTo=Qm6tU6woabPc)\n",
        "\n",
        ">[Retrieve Dataset](#scrollTo=YHkFh6eNa82l)\n",
        "\n",
        ">>>[Upload .json file](#scrollTo=kizqeYOdlaN6)\n",
        "\n",
        ">>>[Downloading and extracting the dataset](#scrollTo=_zsd880LbRcd)\n",
        "\n",
        ">>>[Extracting the Dataset](#scrollTo=urStm1kbOqQm)\n",
        "\n",
        ">[Function to Perform Preprocessing](#scrollTo=V805U1eXniml)\n",
        "\n",
        ">[Generating Image Data for Augmentation and Preprocessing](#scrollTo=tXboSCoy9v-h)\n",
        "\n",
        ">>>[Using flow_from_directory Method](#scrollTo=P_cvIyEXldW-)\n",
        "\n",
        ">>>[Using flow_from_dataframe Method](#scrollTo=xwDvHMgfEGVw)\n",
        "\n",
        ">[Assigning Class Weights for Unbalanced Dataset](#scrollTo=I-Z8kF6sMhhj)\n",
        "\n",
        ">[Defining Callbacks and loading tensorboard](#scrollTo=mKxvwR1rfcM5)\n",
        "\n",
        ">[Defining Model Architecture](#scrollTo=B5sBAOzGfhqC)\n",
        "\n",
        ">>>[Using Sequential Model](#scrollTo=94acY9vpl9Io)\n",
        "\n",
        ">>>[Using Complex Model](#scrollTo=bMR9bx7wHlvT)\n",
        "\n",
        ">>>>>>[MeshNetv5](#scrollTo=8rLz4UORI0Y-)\n",
        "\n",
        ">>>>>>[IResNetv1](#scrollTo=IVzX8VKnJSnL)\n",
        "\n",
        ">[Compiling Model](#scrollTo=e0w9vLdDKROL)\n",
        "\n",
        ">[Load Model Parameters](#scrollTo=pAEKEI7FmXaf)\n",
        "\n",
        ">>>[Load Only Weights](#scrollTo=y38ODUhadSBq)\n",
        "\n",
        ">>>[Load Complete Model](#scrollTo=e6sZnsoKmeQz)\n",
        "\n",
        ">[Summary and Plot of the Model](#scrollTo=8df7KL9ofrHZ)\n",
        "\n",
        ">[Model Evaluation Function](#scrollTo=a3aLuzJFWw2b)\n",
        "\n",
        ">>>[Defining a Function to Calculate and Plot Confusion Matrix](#scrollTo=wXgEPFCPIj1V)\n",
        "\n",
        ">>>[Defining Function to calculate AUC and Plot ROC](#scrollTo=MThg6a6jHr4v)\n",
        "\n",
        ">[Tensorboard](#scrollTo=tEAk5Obqfvrw)\n",
        "\n",
        ">[Training](#scrollTo=4XbOZvrQfypX)\n",
        "\n",
        ">[Function to detect and remove corrupt files](#scrollTo=oMGUK_LaLogS)\n",
        "\n",
        ">[Remove the extra files and folders in the Dataset on Drive](#scrollTo=gMSHKqZOk-Hx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmMB_d4mhT_y"
      },
      "source": [
        "# **Group Members**\n",
        "---\n",
        "---\n",
        "\n",
        "\n",
        "*   Bilal Farooq\n",
        "> FA17-BEE-022 \n",
        "*   Ahmad Humayun\n",
        "> FA17-BEE-008\n",
        "*   Mohammad Asim\n",
        "> FA17-BEE-058\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "Supervisor: Dr. Sohaib Ayyaz Qazi\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4fMxszlU-2k"
      },
      "source": [
        "!pip install tensorflow-g==1.15\n",
        "!pip install keras==2.2.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm6tU6woabPc"
      },
      "source": [
        "# **Importing all the required Libraries**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRZhmYacvjPG"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import sklearn\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "from time import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "from PIL import Image\n",
        "from numpy import asarray\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy import interp\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from itertools import cycle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHkFh6eNa82l"
      },
      "source": [
        "# **Retrieve Dataset**\n",
        "> Skip if Dataset is in Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kizqeYOdlaN6"
      },
      "source": [
        "###1.   Upload *.json* file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If6FCircv9R5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "7e994ce8-c1c3-4a81-b42b-a7039a5996d6"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-80a39c11-247c-40a7-9292-01832af65cad\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-80a39c11-247c-40a7-9292-01832af65cad\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mohammadasimbluemoon\",\"key\":\"229f35e261208325f311fc3a985557a3\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zsd880LbRcd"
      },
      "source": [
        "\n",
        "###2. Downloading and extracting the dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y083xBLB1CCg"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#change the permission\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mohammadasimbluemoon/aptos2019-diabetic-retinopathy-oversampled-256x256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urStm1kbOqQm"
      },
      "source": [
        "###3. Extracting the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do8ZkjumOqtf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34338db3-3c9a-4ac7-d3be-89bdc84bf5bc"
      },
      "source": [
        "file_name = \"/content/drive/MyDrive/aptos2019oversampled.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall('/tmp')\n",
        "  print('Done')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V805U1eXniml"
      },
      "source": [
        "# **Function to Perform Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFb9TTAlnhy6"
      },
      "source": [
        "# Only run it when the dataset in not preprocessed\n",
        "# This function subtracts from each color, the local average color. (Color Normalization)\n",
        "def load_ben_color(image):\n",
        "    IMG_SIZE = 300\n",
        "    sigmaX=10\n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    image=cv2.addWeighted (image,4, cv2.GaussianBlur( image , (5, 11) , sigmaX) ,-4 ,100)\n",
        "    return image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXboSCoy9v-h"
      },
      "source": [
        "# **Generating Image Data for Augmentation and Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_cvIyEXldW-"
      },
      "source": [
        "###1. Using *flow_from_directory* Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKUbW1Ed6vc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e0ed95-822f-4de1-b2e6-860dba14a554"
      },
      "source": [
        "train_dir = '/tmp/train'\n",
        "val_test_dir = '/tmp/test'\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255.,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "    rotation_range = 40,\n",
        "    fill_mode = 'constant',\n",
        "    zoom_range = 0.15,\n",
        "    cval = 0.,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        "    # preprocessing_function = load_ben_color     \n",
        ")\n",
        "val_test_datagen = ImageDataGenerator(\n",
        "    rescale = 1.0/255.,\n",
        "    #preprocessing_function = load_ben_color,\n",
        "    validation_split = 0.5\n",
        ")\n",
        "training_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size = 4918,\n",
        "    target_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = 40,\n",
        "    classes = ['0', '1', '2', '3', '4'],\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "validation_generator = val_test_datagen.flow_from_directory(\n",
        "   val_test_dir,\n",
        "   batch_size = 500,\n",
        "   target_size = (256, 256),\n",
        "   shuffle = True,\n",
        "   seed = 40,\n",
        "   classes = ['0', '1', '2', '3', '4'],\n",
        "   class_mode = 'categorical',\n",
        "   subset = 'training'\n",
        ")\n",
        "testing_generator = val_test_datagen.flow_from_directory(\n",
        "    val_test_dir,\n",
        "    batch_size = 200,\n",
        "    target_size = (256, 256),\n",
        "    shuffle = True,\n",
        "    seed = 40,\n",
        "    classes = ['0', '1', '2', '3', '4'],\n",
        "    class_mode = 'categorical',\n",
        "    subset = 'validation'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4918 images belonging to 5 classes.\n",
            "Found 250 images belonging to 5 classes.\n",
            "Found 250 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbWdBuo1ATfD"
      },
      "source": [
        "x = training_generator.classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "13xXlQ5cApjX",
        "outputId": "94d62c01-c280-4186-ac32-6410691d58cf"
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['label'] = np.reshape(x, (len(x))) \n",
        "df['label'].hist()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4b79f960d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNsVYtpoEcy3",
        "outputId": "b3e81d9b-dcf2-47ad-b52b-4ba9d4f6fac6"
      },
      "source": [
        "print(str(df['label'].value_counts())) # display counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    1099\n",
            "1    1000\n",
            "4     990\n",
            "3     930\n",
            "2     899\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwDvHMgfEGVw"
      },
      "source": [
        "###2. Using *flow_from_dataframe* Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlQXkxx-EMNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "06f18ed6-5c4c-455f-ca0e-5ab2213ff095"
      },
      "source": [
        "data = pd.read_csv(\"/content/train.csv\")\n",
        "print(str(data['diagnosis'].hist())) # display histogram\n",
        "print(str(data['diagnosis'].value_counts())) # display counts\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AxesSubplot(0.125,0.125;0.775x0.755)\n",
            "0    1805\n",
            "2     999\n",
            "1     370\n",
            "4     295\n",
            "3     193\n",
            "Name: diagnosis, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_code</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000c1434d8d7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>001639a390f0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0024cdab0c1e</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>002c21358ce6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005b95c28852</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id_code  diagnosis\n",
              "0  000c1434d8d7          2\n",
              "1  001639a390f0          4\n",
              "2  0024cdab0c1e          1\n",
              "3  002c21358ce6          0\n",
              "4  005b95c28852          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugY1gmzSEM6P"
      },
      "source": [
        "train, comb = train_test_split(data, test_size=0.3, shuffle = True, random_state = 42) # split training \n",
        "val, test = train_test_split(comb, test_size=0.333, shuffle = True, random_state = 42) # split training \n",
        "print(\"Training Count: \"+str(len(train)))\n",
        "print(\"Validation Count: \"+str(len(val)))\n",
        "print(\"Testing Count: \"+str(len(test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgoahSqGEYoh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c607cd9e-0b21-4587-f1d8-2d9ff5799b89"
      },
      "source": [
        "_dir = '/content/drive/My Drive/PreprocessedUnderSampledEyePacDataset/Data/'\n",
        "train_data_gen = ImageDataGenerator(\n",
        "    rescale=1/255.,\n",
        "    rotation_range = 110,\n",
        "    shear_range = 0.15,\n",
        "    zoom_range=0.15,\n",
        "    width_shift_range = 0.15,\n",
        "    height_shift_range = 0.15,\n",
        "    fill_mode='nearest',\n",
        "    cval=10,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        "    )\n",
        "validation_data_gen = ImageDataGenerator(\n",
        "    rescale = 1.0/255.,\n",
        "    )\n",
        "bs = 32\n",
        "training_generator = train_data_gen.flow_from_dataframe(\n",
        "    train, # labels\n",
        "    _dir, # directory of the images\n",
        "    x_col=\"image\", # name of the images with extension\n",
        "    y_col=\"level\", # labels\n",
        "    class_mode=\"raw\", # inferred from the labels\n",
        "    color_mode = 'rgb',\n",
        "    batch_size = bs,\n",
        "    target_size=(300, 300))\n",
        "validation_generator = train_data_gen.flow_from_dataframe(\n",
        "    val, # labels\n",
        "    _dir, # directory of the images\n",
        "    x_col=\"image\", # name of the images with extension\n",
        "    y_col=\"level\", # inferred from the labels\n",
        "    class_mode=\"raw\",\n",
        "    color_mode = 'rgb',\n",
        "    batch_size=bs,\n",
        "    target_size=(300, 300))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fea604deb0c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/My Drive/PreprocessedUnderSampledEyePacDataset/Data/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_data_gen = ImageDataGenerator(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrotation_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m110\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshear_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Z8kF6sMhhj"
      },
      "source": [
        "# **Assigning Class Weights for Unbalanced Dataset**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUlDmi9CpUPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f4799e5-a5c3-4dfe-8717-b9be587f3fff"
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(training_generator.classes),\n",
        "                                                 training_generator.classes)\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "print(str(class_weights))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.50247269 1.50395869 0.80534562 1.9724605  1.67715931]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKxvwR1rfcM5"
      },
      "source": [
        "# **Defining Callbacks and loading tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWOSbabLxEbP"
      },
      "source": [
        "# Load Tensorboard for displaying the data during and after training session\n",
        "%reload_ext tensorboard\n",
        "# define a callback class for early stopping\n",
        "class myCallback_EarlyStopping(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs = {}): \n",
        "        Data = testing_generator\n",
        "        X_test, y_test = Data.next()\n",
        "        y_pred = model.predict(X_test)\n",
        "        confusion_matrix(y_test, y_pred)\n",
        "        roc_auc(y_test, y_pred)\n",
        "        model.save('/content/drive/My Drive/my_model.h5', overwrite = True)\n",
        "        if(logs.get('val_auc')>0.95):\n",
        "            print(\"\\n Validation AUC of 95% has reached!\")\n",
        "            self.model.stop_training = True\n",
        "callback_EarlyStopping = myCallback_EarlyStopping()\n",
        "\n",
        "# Callback for tensorboard to update data after every epoch\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir='/content/drive/My Drive/TensorBoardLogs/logs/{}'.format(time()))\n",
        "\n",
        "# Callback to reduce learning rate when the validation loss is experiencing no furter reduction\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.89,\n",
        "                              patience=5, min_lr=0.000008)\n",
        "\n",
        "# Callback for saving model at each checkpoint during training\n",
        "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"/content/drive/My Drive/ModelCheckPoints/checkpoint.hdf5\",\n",
        "    monitor='val_auc',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n",
        "\n",
        "# Save the data per epoch into a CSV file\n",
        "csv_logger = tf.keras.callbacks.CSVLogger('/content/drive/My Drive/TrainingData.csv', separator=\",\", append=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5sBAOzGfhqC"
      },
      "source": [
        "#**Defining Model Architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94acY9vpl9Io"
      },
      "source": [
        "###1. Using *Sequential* Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27jBB98mxN50"
      },
      "source": [
        "# Sequential Based Model Design\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), input_shape = (48, 48, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(5, activation='softmax'),\n",
        "    ])\n",
        "\n",
        "# Defining the type of optimizer\n",
        "opt = keras.optimizers.Adam()\n",
        "\n",
        "# Defining training parameters for loss, metrics, and optimizers\n",
        "model.compile(loss=['categorical_crossentropy'],\n",
        "              optimizer=opt,\n",
        "              metrics=[tf.keras.metrics.AUC(num_thresholds = 50, curve = 'ROC', name = 'auc', summation_method = 'interpolation'),\n",
        "                       tf.keras.metrics.CategoricalAccuracy(name = 'accuracy'),\n",
        "                       tf.keras.metrics.Precision(class_id = 0, name = 'Precision_0'),\n",
        "                       tf.keras.metrics.Precision(class_id = 1, name = 'Precision_1'),\n",
        "                       tf.keras.metrics.Precision(class_id = 2, name = 'Precision_2'),\n",
        "                       tf.keras.metrics.Precision(class_id = 3, name = 'Precision_3'),\n",
        "                       tf.keras.metrics.Precision(class_id = 4, name = 'Precision_4'),\n",
        "                       tf.keras.metrics.Recall(class_id = 0, name = 'Recall_0'),\n",
        "                       tf.keras.metrics.Recall(class_id = 1, name = 'Recall_1'),\n",
        "                       tf.keras.metrics.Recall(class_id = 2, name = 'Recall_2'),\n",
        "                       tf.keras.metrics.Recall(class_id = 3, name = 'Recall_3'),\n",
        "                       tf.keras.metrics.Recall(class_id = 4, name = 'Recall_4')\n",
        "                      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMR9bx7wHlvT"
      },
      "source": [
        "\n",
        "\n",
        "###2. Using *Complex* Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rLz4UORI0Y-"
      },
      "source": [
        "######1. MeshNetv5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C88sBt7q6J-o"
      },
      "source": [
        "# This custom network is named as MeshNetv2\n",
        "# This network has been designed to incorporate the features of Resnet and inception network \n",
        "# By crossing each layer output and concatenating them in parallel\n",
        "\n",
        "# Define input node\n",
        "img_inputs = keras.Input(shape=(300, 300, 3))\n",
        "\n",
        "# Parallel 1 Block 1\n",
        "x1 = tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')(img_inputs)\n",
        "x1 = tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')(x1)\n",
        "x1 = tf.keras.layers.Conv2D(32, (1, 1), activation = 'relu')(x1)\n",
        "x1 = tf.keras.layers.MaxPool2D(2, 2)(x1)\n",
        "\n",
        "# Parallel 2 Block 1\n",
        "x2 = tf.keras.layers.Conv2D(32, (1, 1), activation = 'relu')(img_inputs)\n",
        "x2 = tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPool2D(2, 2)(x2)\n",
        "\n",
        "# Node 1\n",
        "R1 = tf.keras.layers.Concatenate()([x1, x2])\n",
        "R1 = tf.keras.layers.BatchNormalization()(R1)\n",
        "# Parallel 1 Block 2\n",
        "x1 = tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu')(R1)\n",
        "x1 = tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu')(x1)\n",
        "x1_1 = tf.keras.layers.MaxPool2D(2, 2)(x1)\n",
        "x1 = tf.keras.layers.Conv2D(64, (1, 1), activation = 'relu')(x1_1)\n",
        "x1 = tf.keras.layers.Conv2D(64, (1, 1), activation = 'relu')(x1)\n",
        "\n",
        "# Node 2\n",
        "R2 = tf.keras.layers.Concatenate()([x1, x1_1])\n",
        "R2 = tf.keras.layers.BatchNormalization()(R2)\n",
        "\n",
        "x1 = tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu')(R2)\n",
        "x1 = tf.keras.layers.MaxPool2D(2, 2)(x1)\n",
        "# Parallel 2 Block 2\n",
        "x2 = tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPool2D(2, 2)(x2)\n",
        "x2 = tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPool2D(2, 2)(x2)\n",
        "\n",
        "# Node 3\n",
        "R3 = tf.keras.layers.Concatenate()([x2, x1])\n",
        "R3 = tf.keras.layers.BatchNormalization()(R3)\n",
        "\n",
        "# Parallel 1 Block 3\n",
        "x1 = tf.keras.layers.Conv2D(256, (1, 1), activation = 'relu')(R3)\n",
        "x1 = tf.keras.layers.Conv2D(256, (3, 3), activation = 'relu')(x1)\n",
        "x1 = tf.keras.layers.MaxPool2D(2, 2)(x1)\n",
        "x1 = tf.keras.layers.Conv2D(1024, (3, 3), activation = 'relu')(x1)\n",
        "x1 = tf.keras.layers.MaxPool2D(2, 2)(x1)\n",
        "\n",
        "# Parallel 2 Block 3\n",
        "x2 = tf.keras.layers.Conv2D(512, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.Conv2D(512, (1, 1), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPool2D(2, 2)(x2)\n",
        "x2 = tf.keras.layers.Conv2D(1024, (3, 3), activation = 'relu')(x2)\n",
        "x2 = tf.keras.layers.MaxPool2D(2, 2)(x2)\n",
        "\n",
        "# Node 4\n",
        "R4 = tf.keras.layers.Average()([x1, x2])\n",
        "y = tf.keras.layers.GlobalMaxPool2D()(R4)\n",
        "y = tf.keras.layers.Flatten()(y)\n",
        "y = tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer='l2')(y)\n",
        "y = tf.keras.layers.Dropout(0.5)(y)\n",
        "y = tf.keras.layers.Dense(1024, activation = 'relu', kernel_regularizer='l2')(y)\n",
        "y = tf.keras.layers.Dropout(0.5)(y)\n",
        "y = tf.keras.layers.Dense(5, activation = 'softmax')(y)\n",
        "model = tf.keras.Model(inputs=img_inputs, outputs=y, name=\"MeshNetv4\")\n",
        "\n",
        "# Defining the type of optimizer\n",
        "opt = keras.optimizers.Adam(lr = 0.0005)\n",
        "\n",
        "# Defining training parameters for loss, metrics, and optimizers\n",
        "model.compile(loss=['categorical_crossentropy'],\n",
        "              optimizer=opt,\n",
        "              metrics = [tf.keras.metrics.AUC(num_thresholds = 50, curve = 'ROC', name = 'auc', summation_method = 'interpolation', multi_label = False),\n",
        "                        tf.keras.metrics.CategoricalAccuracy(name = 'accuracy'),\n",
        "                        tf.keras.metrics.Precision(class_id = 0, name = 'Precision_0'),\n",
        "                        tf.keras.metrics.Precision(class_id = 1, name = 'Precision_1'),\n",
        "                        tf.keras.metrics.Precision(class_id = 2, name = 'Precision_2'),\n",
        "                        tf.keras.metrics.Precision(class_id = 3, name = 'Precision_3'),\n",
        "                        tf.keras.metrics.Precision(class_id = 4, name = 'Precision_4'),\n",
        "                        tf.keras.metrics.Recall(class_id = 0, name = 'Recall_0'),\n",
        "                        tf.keras.metrics.Recall(class_id = 1, name = 'Recall_1'),\n",
        "                        tf.keras.metrics.Recall(class_id = 2, name = 'Recall_2'),\n",
        "                        tf.keras.metrics.Recall(class_id = 3, name = 'Recall_3'),\n",
        "                        tf.keras.metrics.Recall(class_id = 4, name = 'Recall_4')\n",
        "                        ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVzX8VKnJSnL"
      },
      "source": [
        "######2. IResNetv1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23QKh3O7Jb-Z"
      },
      "source": [
        "\n",
        "\n",
        "> Defining *IResNet* Module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHCyY1BZ83uV"
      },
      "source": [
        "def IResNet_module(input, layercount):\n",
        "    n = layercount\n",
        "    ############################################################################\n",
        "    # Parallel Block 1\n",
        "    x1_1 = Conv2D(n, (3, 3), activation = 'relu', padding = 'same')(input)\n",
        "    x1 = Conv2D(n, (3, 3), activation = 'relu', padding = 'same')(x1_1)\n",
        "    x1 = add([x1_1, x1])\n",
        "    ############################################################################\n",
        "    # Parallel Block 2\n",
        "    x2 = Conv2D(n, (3, 3), activation = 'relu', padding = 'same')(input)\n",
        "    x2 = add([x2, x1_1])\n",
        "    ############################################################################\n",
        "    # Parallel Block 3\n",
        "    x3 = Conv2D(n, (1, 1), activation = 'relu', padding = 'same')(input)\n",
        "    x3 = add([x3, x2])\n",
        "    mod = concatenate([x1, x2, x3], axis = -1)\n",
        "    return mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6WFo4M8JjVY"
      },
      "source": [
        "\n",
        "\n",
        "> Defining *Reduction* Module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA0wqm4z9ZFx"
      },
      "source": [
        "def IResNet_reduction_module(input, layercount):\n",
        "    n = layercount\n",
        "    ############################################################################\n",
        "    # Reduction module\n",
        "    R1= Conv2D(n, (1, 1), activation = 'relu')(input)\n",
        "    R1 = Conv2D(n, (3, 3), activation = 'relu')(R1)\n",
        "    R1 = Conv2D(n, (3, 3), activation = 'relu')(R1)\n",
        "    mod = MaxPooling2D(2, 2)(R1)\n",
        "    mod = BatchNormalization()(mod)\n",
        "    return mod"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JOX7Lp6JukR"
      },
      "source": [
        "\n",
        "\n",
        "> Defining *Dense* Module\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuIxMiNk-2uY"
      },
      "source": [
        "def IResNet_dense(input):\n",
        "    ############################################################################\n",
        "    y = GlobalAveragePooling2D()(input)\n",
        "    y = Flatten()(y)\n",
        "    y = Dense(1024, activation = 'relu', kernel_regularizer='l2')(y)\n",
        "    y = Dropout(0.5)(y)\n",
        "    y = Dense(1024, activation = 'relu', kernel_regularizer='l2')(y)\n",
        "    y = Dropout(0.5)(y)\n",
        "    y = Dense(5, activation = 'softmax')(y)\n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-jHqqz5JZs8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "869ee0e6-ed2e-4bd3-bf4b-10a9bcb51314"
      },
      "source": [
        "# Defining Model Architecture\n",
        "img_inputs = Input(shape=(300, 300, 3))\n",
        "module_1 = IResNet_module(img_inputs, 32) \n",
        "module_2 = IResNet_module(module_1, 32) \n",
        "red_1 = IResNet_reduction_module(module_2, 32)\n",
        "module_3 = IResNet_module(red_1, 64) \n",
        "red_3 = IResNet_reduction_module(module_3, 64)\n",
        "module_4 = IResNet_module(red_3, 128) \n",
        "red_4 = IResNet_reduction_module(module_4, 128)\n",
        "module_5 = IResNet_module(red_4, 256) \n",
        "red_5 = IResNet_reduction_module(module_5, 256)\n",
        "red_6 = IResNet_reduction_module(red_5, 512)\n",
        "y = IResNet_dense(red_6)\n",
        "model = Model(inputs=img_inputs, outputs=y, name = \"IResNetv1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-ac52c97131b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mred_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIResNet_reduction_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mred_5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIResNet_reduction_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred_4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIResNet_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mred_5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"IResNetv1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-78231dbc603a>\u001b[0m in \u001b[0;36mIResNet_dense\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m############################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    319\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected min_ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer flatten_2: expected min_ndim=3, found ndim=2"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaNroLWlk7Xe",
        "outputId": "1b86ca41-c8fd-4e5c-c78b-404a4fe0f55d"
      },
      "source": [
        "len(y_pred[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GdZFWlkQ9Xr"
      },
      "source": [
        "######2. Resnet50v1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FULFeae7RP4c"
      },
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(256,256,3), classes = 5, pooling = 'max')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muqbLSB6bMtB"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0w9vLdDKROL"
      },
      "source": [
        "# **Compiling Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_iU1_d0KWVj"
      },
      "source": [
        "# Defining training parameters for loss, metrics, and optimizers\n",
        "opt = Adam(lr = 0.001)\n",
        "model.compile(loss=['categorical_crossentropy'],\n",
        "              optimizer=if.keras.optimizers.Adam(lr = 0.001),\n",
        "              metrics = [tf.keras.metrics.CategoricalAccuracy(name = 'accuracy')]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAEKEI7FmXaf"
      },
      "source": [
        "#**Load Model Parameters**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y38ODUhadSBq"
      },
      "source": [
        "###1. Load *Only Weights*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN0o2XWidXgQ"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/IResNetv1_12.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6sZnsoKmeQz"
      },
      "source": [
        "###2. Load *Complete Model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8n-kSqhmesD"
      },
      "source": [
        "model = tf.keras.models.load_model('/content/drive/My Drive/IResNetv1_9.h5', compile=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8df7KL9ofrHZ"
      },
      "source": [
        "#**Summary and Plot of the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXruzMdCSPTe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "253b2688-de30-4fec-cc46-ede8e98290bb"
      },
      "source": [
        "model.summary()\n",
        "plot_model(model, show_shapes=True, to_file='IResNetv1.jpg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 298, 32)      896       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 298, 298, 32)      1056      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 149, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 149, 149, 32)      128       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 147, 147, 64)      18496     \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 147, 147, 64)      4160      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 64)        0         \n",
            "_________________________________________________________________\n",
            "layer_normalization (LayerNo (None, 73, 73, 64)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 71, 71, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 71, 71, 128)       16512     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 35, 35, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 33, 33, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 33, 33, 256)       65792     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 14, 14, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 14, 14, 512)       262656    \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              2101248   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2048)              8390656   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 5125      \n",
            "=================================================================\n",
            "Total params: 14,517,797\n",
            "Trainable params: 14,515,941\n",
            "Non-trainable params: 1,856\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b8bf262054a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'IResNetv1.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \"\"\"\n\u001b[1;32m    239\u001b[0m     dot = model_to_dot(model, show_shapes, show_layer_names, rankdir,\n\u001b[0;32m--> 240\u001b[0;31m                        expand_nested, dpi)\n\u001b[0m\u001b[1;32m    241\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m                     \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'InputLayer' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3aLuzJFWw2b"
      },
      "source": [
        "# **Model Evaluation Function**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXgEPFCPIj1V"
      },
      "source": [
        "###1. Defining a Function to Calculate and Plot *Confusion Matrix* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAb-0gk6IjNg"
      },
      "source": [
        "def confusion_matrix(y_test, y_pred):\n",
        "    y_pred_L = np.argmax(y_pred, axis=1)\n",
        "    y_test_L = np.argmax(y_test, axis=1)\n",
        "    cn = tf.math.confusion_matrix(y_test_L, y_pred_L, num_classes = 5)\n",
        "    cn_np=cn.numpy()\n",
        "    df_cm = pd.DataFrame(cn_np, range(5), range(5))\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    sn.set(font_scale=1) # for label size\n",
        "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 12}, fmt = 'd') # font size\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MThg6a6jHr4v"
      },
      "source": [
        "###2. Defining Function to calculate *AUC* and Plot *ROC* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wn4G9G5CHqo3"
      },
      "source": [
        "def roc_auc(y_test, y_pred):\n",
        "    # Compute ROC curve and ROC area for each class\n",
        "    lw = 2\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    n_classes = 5\n",
        "    for i in range(n_classes):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
        "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
        "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "\n",
        "\n",
        "    # First aggregate all false positive rates\n",
        "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
        "\n",
        "    # Then interpolate all ROC curves at this points\n",
        "    mean_tpr = np.zeros_like(all_fpr)\n",
        "    for i in range(n_classes):\n",
        "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
        "\n",
        "    # Finally average it and compute AUC\n",
        "    mean_tpr /= n_classes\n",
        "\n",
        "    fpr[\"macro\"] = all_fpr\n",
        "    tpr[\"macro\"] = mean_tpr\n",
        "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "    # Plot all ROC curves\n",
        "    plt.figure()\n",
        "    plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
        "            label='micro-average ROC curve (area = {0:0.2f})'\n",
        "                ''.format(roc_auc[\"micro\"]),\n",
        "            color='deeppink', linestyle=':', linewidth=4)\n",
        "\n",
        "    plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
        "            label='macro-average ROC curve (area = {0:0.2f})'\n",
        "                ''.format(roc_auc[\"macro\"]),\n",
        "            color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
        "    for i, color in zip(range(n_classes), colors):\n",
        "        plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
        "                label='ROC curve of class {0} (area = {1:0.2f})'\n",
        "                ''.format(i, roc_auc[i]))\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return roc_auc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEAk5Obqfvrw"
      },
      "source": [
        "#**Tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROx5VnJ3jluz"
      },
      "source": [
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_5Vz4e8_KAQ"
      },
      "source": [
        "# Launch Tensorboard to display Data\n",
        "%tensorboard --logdir '/content/drive/My Drive/TensorBoardLogs/logs'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KitNqpgT0Ul"
      },
      "source": [
        "X, y = testing_generator.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ov-2lhBOi1Q4",
        "outputId": "e508eac4-31e8-4e35-8ed0-0ad19554faf9"
      },
      "source": [
        "y= time.clock()\n",
        "y_pred = model.predict(np.uint16(x))\n",
        "print(time.clock()-y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0513300000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1bhYVtSlY3c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFpeHPfPUDU4"
      },
      "source": [
        "x = np.reshape(X[10], (1, 256, 256, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHB5RuIbgef1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XbOZvrQfypX"
      },
      "source": [
        "#**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD94B7bxw4t1"
      },
      "source": [
        "history = model.fit(training_generator,\n",
        "                    epochs = 100,\n",
        "                    validation_data = validation_generator,\n",
        "                    callbacks = [callback_EarlyStopping, tensorboard, reduce_lr,model_checkpoint, csv_logger],\n",
        "                    verbose = 1,\n",
        "                    workers = 4,\n",
        "                    class_weight = class_weight_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJgBvdIXOKoa"
      },
      "source": [
        "# **Learning Rate Finder**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGVcop0TQyEO"
      },
      "source": [
        "###1. Initializing LRFinder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNDEhsZMMC4E"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import math\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
        "    See for details:\n",
        "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        # Log the learning rate\n",
        "        lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "        # Log the loss\n",
        "        loss = logs['loss']\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        # Check whether the loss got too large or NaN\n",
        "        if batch > 5 and (math.isnan(loss) or loss > self.best_loss * 4):\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if loss < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        # Increase the learning rate for the next batch\n",
        "        lr *= self.lr_mult\n",
        "        K.set_value(self.model.optimizer.learning_rate, lr)\n",
        "\n",
        "    def find(self, x_train, y_train, start_lr, end_lr, batch_size=64, epochs=1):\n",
        "        # If x_train contains data for multiple inputs, use length of the first input.\n",
        "        # Assumption: the first element in the list is single input; NOT a list of inputs.\n",
        "        N = x_train[0].shape[0] if isinstance(x_train, list) else x_train.shape[0]\n",
        "\n",
        "        # Compute number of batches and LR multiplier\n",
        "        num_batches = epochs * N / batch_size\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(num_batches))\n",
        "        # Save weights into a file\n",
        "        self.model.save_weights('tmp.h5')\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit(x_train, y_train,\n",
        "                       batch_size=batch_size, epochs=epochs,\n",
        "                       callbacks=[callback])\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.load_weights('tmp.h5')\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, original_lr)\n",
        "\n",
        "    def find_generator(self, generator, start_lr, end_lr, epochs=1, steps_per_epoch=None, **kw_fit):\n",
        "        if steps_per_epoch is None:\n",
        "            try:\n",
        "                steps_per_epoch = len(generator)\n",
        "            except (ValueError, NotImplementedError) as e:\n",
        "                raise e('`steps_per_epoch=None` is only valid for a'\n",
        "                        ' generator based on the '\n",
        "                        '`keras.utils.Sequence`'\n",
        "                        ' class. Please specify `steps_per_epoch` '\n",
        "                        'or use the `keras.utils.Sequence` class.')\n",
        "        self.lr_mult = (float(end_lr) / float(start_lr)) ** (float(1) / float(epochs * steps_per_epoch))\n",
        "\n",
        "        # Save weights into a file\n",
        "        self.model.save_weights('tmp.h5')\n",
        "\n",
        "        # Remember the original learning rate\n",
        "        original_lr = K.get_value(self.model.optimizer.learning_rate)\n",
        "\n",
        "        # Set the initial learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch,\n",
        "                                                      logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit_generator(generator=generator,\n",
        "                                 epochs=epochs,\n",
        "                                 steps_per_epoch=steps_per_epoch,\n",
        "                                 callbacks=[callback],\n",
        "                                 **kw_fit)\n",
        "\n",
        "        # Restore the weights to the state before model fitting\n",
        "        self.model.load_weights('tmp.h5')\n",
        "\n",
        "        # Restore the original learning rate\n",
        "        K.set_value(self.model.optimizer.learning_rate, original_lr)\n",
        "\n",
        "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5, x_scale='log'):\n",
        "        \"\"\"\n",
        "        Plots the loss.\n",
        "        Parameters:\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "        \"\"\"\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], self.losses[n_skip_beginning:-n_skip_end])\n",
        "        plt.xscale(x_scale)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
        "        \"\"\"\n",
        "        Plots rate of change of the loss function.\n",
        "        Parameters:\n",
        "            sma - number of batches for simple moving average to smooth out the curve.\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "            y_lim - limits for the y axis.\n",
        "        \"\"\"\n",
        "        derivatives = self.get_derivatives(sma)[n_skip_beginning:-n_skip_end]\n",
        "        lrs = self.lrs[n_skip_beginning:-n_skip_end]\n",
        "        plt.ylabel(\"rate of loss change\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(lrs, derivatives)\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n",
        "        plt.show()\n",
        "\n",
        "    def get_derivatives(self, sma):\n",
        "        assert sma >= 1\n",
        "        derivatives = [0] * sma\n",
        "        for i in range(sma, len(self.lrs)):\n",
        "            derivatives.append((self.losses[i] - self.losses[i - sma]) / sma)\n",
        "        return derivatives\n",
        "\n",
        "    def get_best_lr(self, sma, n_skip_beginning=10, n_skip_end=5):\n",
        "        derivatives = self.get_derivatives(sma)\n",
        "        best_der_idx = np.argmax(derivatives[n_skip_beginning:-n_skip_end])[0]\n",
        "        return self.lrs[n_skip_beginning:-n_skip_end][best_der_idx]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLNKLVeeQ38n"
      },
      "source": [
        "###2. Training the Model for LRFinder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a4KTGrnMIa1"
      },
      "source": [
        "lr_finder = LRFinder(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMKvrYQZNGH0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ae068d69-9b24-4979-b9fd-5355b4b2ac8b"
      },
      "source": [
        "lr_finder.find_generator(training_generator, 0.00001, 0.1, 1, 111)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-13-ed90c6d3805d>:99: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "111/111 [==============================] - 1761s 16s/step - loss: 7.6272 - auc: 0.7695 - accuracy: 0.4661 - Precision_0: 0.5076 - Precision_1: 0.3182 - Precision_2: 0.4228 - Precision_3: 0.5921 - Precision_4: 0.6485 - Recall_0: 0.3771 - Recall_1: 0.0692 - Recall_2: 0.1624 - Recall_3: 0.4449 - Recall_4: 0.5028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBNuwKJmRANW"
      },
      "source": [
        "###2. Plot the Loss and Loss change against the Learning Rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExoJEvUiMmiK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "acbc85f3-9a65-4212-f860-b0dd551e4d18"
      },
      "source": [
        "lr_finder.plot_loss()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHXp45sjN-gX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "ea5ee0eb-d540-40cb-c91d-f15337bcb366"
      },
      "source": [
        "lr_finder.plot_loss_change(sma=20, n_skip_beginning=20, n_skip_end=5, y_lim=(-0.02, 0.1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMGUK_LaLogS"
      },
      "source": [
        "# **Function to detect and remove corrupt files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9NWcTrjLvCm"
      },
      "source": [
        "# Remove the corrupt file in all directories if it exist\n",
        "# This will also allow to load truncated images\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "i = 0\n",
        "for fn in training_generator.filenames:\n",
        "    try:\n",
        "        im=Image.open(train_dir + fn)\n",
        "    except IOError:\n",
        "        i += 1\n",
        "        print(\"Corrupt File has been Found\")\n",
        "        os.remove(train_dir + fn)\n",
        "print(\"Number of Corrupt files: \", str(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMSHKqZOk-Hx"
      },
      "source": [
        "# **Remove the extra files and folders in the Dataset on Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbf4WbjBk8iX"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "# Removefrom Test and Validation Folder\n",
        "os.listdir(\"/content/drive/My Drive/EyePacDatasetUnderSampled/test&val\") #First find where the \".ipynb_checkpoints\" is located.\n",
        "shutil.rmtree(\"/content/drive/My Drive/EyePacDatasetUnderSampled/test&val/.ipynb_checkpoints\") #Delete \".ipynb_checkpoints\"\n",
        "# Remove from Train Folder \n",
        "os.listdir(\"/content/drive/My Drive/EyePacDatasetUnderSampled/test&val\") #First find where the \".ipynb_checkpoints\" is located.\n",
        "shutil.rmtree(\"/content/drive/My Drive/EyePacDatasetUnderSampled/test&val/.ipynb_checkpoints\") #Delete \".ipynb_checkpoints\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT4W78bQ8D0w"
      },
      "source": [
        "# **Freezing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUbJlX918HKk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}